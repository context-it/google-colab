{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install java & spark"
      ],
      "metadata": {
        "id": "4vc1Hj6fUXOn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhOPsHjgUNCs",
        "outputId": "d0da88ab-ef99-40b4-deb7-2f79785fc205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-26 15:53:41--  https://dlcdn.apache.org/spark/spark-3.5.4/spark-3.5.4-bin-hadoop3.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400879762 (382M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.5.4-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.5.4-bin-had 100%[===================>] 382.31M   205MB/s    in 1.9s    \n",
            "\n",
            "2025-01-26 15:53:58 (205 MB/s) - ‘spark-3.5.4-bin-hadoop3.tgz’ saved [400879762/400879762]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!apt-get install openjdk-17-jdk-headless -qq > /dev/null\n",
        "!wget https://dlcdn.apache.org/spark/spark-3.5.4/spark-3.5.4-bin-hadoop3.tgz -O spark-3.5.4-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.4-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## configure spark env"
      ],
      "metadata": {
        "id": "aU9GUIkGUWHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.4-bin-hadoop3\""
      ],
      "metadata": {
        "id": "72rFlzcoUS8X"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q pyspark"
      ],
      "metadata": {
        "id": "QLYZo4u_Uhbd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = (SparkSession.builder\n",
        "        .master(\"local\")\n",
        "        .appName(\"My Spark Application\")\n",
        "        .getOrCreate())\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "8VqQQSRuUkEJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "_kDMyWGFUpyO",
        "outputId": "160e63f1-888e-4c1b-a896-1579c70ea665"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7c0c12b94350>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://d81c3c375e35:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.4</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>My Spark Application</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Docs\n",
        "\n",
        "### Load\n",
        "\n",
        "https://spark.apache.org/docs/3.5.4/sql-data-sources-csv.html\n",
        "\n"
      ],
      "metadata": {
        "id": "6Og9dfESWBco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p var/\n",
        "!echo \"id;name;age\" > var/data.csv\n",
        "!echo \"1;Alice;25\" >> var/data.csv\n",
        "!echo \"2;Bob;30\" >> var/data.csv"
      ],
      "metadata": {
        "id": "fsDE4ydWUt8M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"var/data.csv\", header=True, sep=\";\")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_RcY4KnWieW",
        "outputId": "08ba1b06-aee1-4ca2-a6d9-01b63abd4ebc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+---+\n",
            "| id| name|age|\n",
            "+---+-----+---+\n",
            "|  1|Alice| 25|\n",
            "|  2|  Bob| 30|\n",
            "+---+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"people\")"
      ],
      "metadata": {
        "id": "dhJn6srMWrjl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('''\n",
        "  select\n",
        "    id,\n",
        "    md5(id) id_hash,\n",
        "    name,\n",
        "    age,\n",
        "    (100-age) years_to_100\n",
        "  from people\n",
        "''').show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4seR7c3Wxm7",
        "outputId": "ba33d319-1215-4d9d-a8fc-d11f7fd87601"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------------------+-----+---+------------+\n",
            "|id |id_hash                         |name |age|years_to_100|\n",
            "+---+--------------------------------+-----+---+------------+\n",
            "|1  |c4ca4238a0b923820dcc509a6f75849b|Alice|25 |75.0        |\n",
            "|2  |c81e728d9d4c2f636f067f89cc14862c|Bob  |30 |70.0        |\n",
            "+---+--------------------------------+-----+---+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NDSwXuZGW9yJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}